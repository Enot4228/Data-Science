{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTnbWDwjNqBj"
   },
   "source": [
    "# Stacking\n",
    "\n",
    "Несмотря на то, что в открытом доступе существует довольно много реализаций стекинга, некоторые из которых даже представлены в виде библиотечных функций, лучше сделать собственную. Стекинг - не классический алгоритм решения задачи, а скорее набор правил для помощи в решении задачи другим алгоритмам. Если вы серьезно займетесь машинным обучением, рано или поздно вам скорее всего захочется что-нибудь поменять в этом наборе правил, поэтому собственная реализация с понятным вам кодом будет как нельзя кстати."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0AKW53hNqBk"
   },
   "source": [
    "В этом домашнем задании вы создадите собственную функцию для блендинга/классического стекинга моделей, которая пригодится вам в дальнейшем.\n",
    "\n",
    "Ниже вы увидите заготовку для функции, где:\n",
    "\n",
    "- models - список объектов базовых алгоритмов\n",
    "\n",
    "- meta_alg - мета-алгоритм\n",
    "\n",
    "data_train, targets_train, data_test, targets_test - тренировочные и тестовые признаки и целевые переменные\n",
    "\n",
    "- test_size - размер тестовых данных для блендинга в промежутке (0, 1)\n",
    "\n",
    "- cv - количество разбиений для кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vVIUJhUMNqBl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BDRkf96PNqBo"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-a175c9871b8f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-a175c9871b8f>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def stacking(models, meta_alg, data_train, targets_train, data_test, targets_test=None, test_size=None, cv=5):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMaQZPnxNqBr"
   },
   "source": [
    "### 1.\n",
    "В следующей ячейке в теле функции определен условный оператор if-else. После elif вместо pass пропишите код из лекции с некоторыми новыми вставками в таком порядке: деление data_train и targets_train на тренировочные и валидационные данные с помощью функции train_test_split, где test_size=test_size из определения функции; определение матрицы meta_mtrx; цикл, в котором заполняется meta_mtrx: сначала строка, где модель обучается с помощью метода fit на тренировочных данных из разбиения, затем строка, где матрица заполняется значениями предсказаний моделей на валидационных данных. На этом цикл заканчивается.\n",
    "\n",
    "После цикла добавьте строку с методом fit мета-алгоритма: обучите его на значениях полученной матрицы meta_mtrx и целевой переменной для валидационных данных.\n",
    "\n",
    "Определите матрицу meta_mtrx_test. Напишите цикл, где эта матрица заполняется предсказаниями базовых моделей на тестовых данных data_test.\n",
    "\n",
    "После цикла сделайте предсказания мета-алгоритма для значений матрицы meta_mtrx_test.\n",
    "\n",
    "Дополните код еще одним оператором if, который будет проверять, существуют ли данные targets_test для проверки качества работы модели на тестовых данных: если targets_test не является None, тогда выведите метрику roc_auc_score для предсказаний мета-алгоритма на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "u0dJcqB5NqBr"
   },
   "outputs": [],
   "source": [
    "def stacking(models, meta_alg, data_train, targets_train, data_test, targets_test=None, random_state=None, test_size=None, cv=5):\n",
    "    if test_size is None:\n",
    "        pass\n",
    "    \n",
    "    elif test_size > 0 and test_size < 1:\n",
    "        train, valid, train_true, valid_true = train_test_split(data_train, \n",
    "                                                                targets_train,\n",
    "                                                                test_size=test_size,\n",
    "                                                                random_state=17)\n",
    "        meta_mtrx = np.empty((valid.shape[0], len(models)))\n",
    "        for n, model in enumerate(models):\n",
    "            model_tr = model.fit(train)\n",
    "            meta_mtrx[:, n] = model.predict(valid)\n",
    "            predicted = model.predict(data_test)\n",
    "        meta_alg = meta.fit(meta_mtrx, valid_true)\n",
    "        \n",
    "        meta_mtrx_test = np.empty((data_test.shape[0], len(models)))\n",
    "        for n, model in enumerate(models):\n",
    "            meta_mtrx_test[:, n] = model.predict(data_test)\n",
    "            \n",
    "        meta_predict = meta.predict(meta_mtrx_test)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"test_size must be between 0 and 1\")\n",
    "        \n",
    "    if targets_test != None:\n",
    "            print(f'AUC: {roc_auc_score(targets_test, predicted)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZ7ssAZ-NqBu"
   },
   "source": [
    "### 2.\n",
    "Теперь напишите код стекинга вместо pass после оператора if.\n",
    "\n",
    "Сразу определите матрицу meta_mtrx. Напишите цикл для заполнения матрицы: сначала напишите строку, где каждый столбец метапризнаков (для каждой модели) заполняется с помощью функции cross_val_predict(base_algotithm, data_train, targets_train, cv, method='predict'); следующая строка - обучите каждый базовый алгоритм на полном тренировочном датасете.\n",
    "\n",
    "После цикла обучите мета-алгоритм на матрице метапризнаков meta_mtrx. Определите матрицу meta_mtrx_test.\n",
    "\n",
    "Напишите второй цикл, где матрица meta_mtrx_test заполняется предсказаниями базовых моделей на тестовых данных data_test.\n",
    "\n",
    "После цикла сделайте предсказания мета-алгоритма для значений матрицы meta_mtrx_test.\n",
    "\n",
    "Так же, как и для блендинга, напишите код проверки для targets_test и выведите roc_auc_score, если это возможно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1aYbDelYNqBu"
   },
   "outputs": [],
   "source": [
    "def stacking(models, meta_alg, data_train, targets_train, data_test, targets_test=None, random_state=None, test_size=None, cv=5):\n",
    "    if test_size is None:\n",
    "        \n",
    "        meta_mtrx = meta_mtrx = np.empty((data_train.shape[0], len(models)))\n",
    "        for n, model in enumerate(models):\n",
    "            meta_mtrx[:, n] = cross_val_predict(estimator=model, X=data_train, y=targets_train, cv=cv, method='predict')\n",
    "            model = model.fit(data_train, targets_train)\n",
    "            predicted = model.predict(data_test)\n",
    "        meta_model = meta_alg.fit(meta_mtrx, targets_train)\n",
    "        \n",
    "        meta_mtrx_test = meta_mtrx_test = np.empty((data_test.shape[0], len(models)))\n",
    "        for n, model in enumerate(models):\n",
    "            meta_mtrx_test[:, n] = model.predict(data_test)\n",
    "            \n",
    "        meta_predict = meta_alg.predict(meta_mtrx_test)\n",
    "    \n",
    "    elif test_size > 0 and test_size < 1:\n",
    "        train, valid, train_true, valid_true = train_test_split(data_train, \n",
    "                                                                targets_train,\n",
    "                                                                test_size=test_size,\n",
    "                                                                random_state=17)\n",
    "        meta_mtrx = np.empty((valid.shape[0], len(models)))\n",
    "        for n, model in enumerate(models):\n",
    "            model_tr = model.fit(train, train_true)\n",
    "            meta_mtrx[:, n] = model.predict(valid)\n",
    "            predicted = model.predict(data_test)\n",
    "        meta_model = meta_alg.fit(meta_mtrx, valid_true)\n",
    "        \n",
    "        meta_mtrx_test = np.empty((data_test.shape[0], len(models)))\n",
    "        for n, model in enumerate(models):\n",
    "            meta_mtrx_test[:, n] = model.predict(data_test)\n",
    "            \n",
    "        meta_predict = meta_alg.predict(meta_mtrx_test)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"test_size must be between 0 and 1\")\n",
    "        \n",
    "    if targets_test is not None:\n",
    "        print(f'AUC: {roc_auc_score(targets_test, predicted)}')\n",
    "        print(f'Predict: {predicted}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktP_ZympNqBx"
   },
   "source": [
    "### 3.\n",
    "Базовая функция стекинга готова. Теперь проверим, как она работает. Ниже представлен уже знакомый нам датасет Titanic, разделенный на тренировочный и тестовый датасеты; предопределенные базовые алгоритмы и мета-алгоритм. Ваша задача - составить список базовых алгоритмов и запустить функцию в трех различных вариантах (при этом в каждом из них все значения data_train, targets_train, data_test, targets_test должны быть определены):\n",
    "\n",
    "1. Вызвать исключение \"test_size must be between 0 and 1\".\n",
    "\n",
    "2. Установить test_size=0.3; вывести AUC и массив полученных предсказаний.\n",
    "\n",
    "3. Оставить test_size=None; вывести AUC и массив полученных предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2kJT4LjRNqBx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:36:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC: 0.6197983975187387\n",
      "Predict: [0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "titanic = pd.read_csv('titanic.csv')\n",
    "targets = titanic.Survived\n",
    "data = titanic.drop(columns='Survived')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, \n",
    "                                                    targets,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=17)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "lr = LogisticRegression(random_state=17)\n",
    "svc = SVC(random_state=17)\n",
    "meta = XGBClassifier(n_estimators=40)\n",
    "\n",
    "models = [knn, lr, svc]\n",
    "\n",
    "stacking(models=models, meta_alg=meta, data_train=x_train, targets_train=y_train, data_test=x_test, targets_test=y_test, random_state=None, test_size=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "qbHZDCAiNqB0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:51:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC: 0.5478159731196692\n",
      "Predict: [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "stacking(models=models, meta_alg=meta, data_train=x_train, targets_train=y_train, data_test=x_test, targets_test=y_test, random_state=None, test_size=0.3, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:51:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "AUC: 0.646291031274231\n",
      "Predict: [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "stacking(models=models, meta_alg=meta, data_train=x_train, targets_train=y_train, data_test=x_test, targets_test=y_test, random_state=None, test_size=None, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QT9CNfbBNqB2"
   },
   "source": [
    "По мере того, как вы будете использовать эту функцию, вам могут пригодиться такие дополнительные параметры как: random_state, который позволит делать воспроизводимые модели; metrics - список метрик, которые могут быть вычислены; grid_search, который может производить поиск лучших параметров для алгоритмов, и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading https://files.pythonhosted.org/packages/3a/e7/3bac01547d2ed3d308ac92a0878fbdb0ed0f3d41fb1906c319ccbba1bfbc/kaggle-1.5.12.tar.gz (58kB)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\lib\\site-packages (from kaggle) (2019.9.11)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\admin\\anaconda3\\lib\\site-packages (from kaggle) (2.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (from kaggle) (2.22.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\lib\\site-packages (from kaggle) (4.36.1)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading https://files.pythonhosted.org/packages/7e/e2/0c8be1e3b237d11f10963c7cef82e4d98d70ca6e176f3922dddf7bfc7026/python_slugify-5.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: urllib3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from kaggle) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.8)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/a5/c0b6468d3824fe3fde30dbb5e1f687b291608f9473681bbf7dabbf5a87d7/text_unidecode-1.3-py2.py3-none-any.whl (78kB)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.12-cp37-none-any.whl size=73053 sha256=ed40e64653d88ee6ce2f42fa89fb237753298b22f7f3a719957ecb9f63933052\n",
      "  Stored in directory: C:\\Users\\admin\\AppData\\Local\\pip\\Cache\\wheels\\a1\\6a\\26\\d30b7499ff85a4a4593377a87ecf55f7d08af42f0de9b60303\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.12 python-slugify-5.0.2 text-unidecode-1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "jun_ml_extra_tech_stack-hw.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
